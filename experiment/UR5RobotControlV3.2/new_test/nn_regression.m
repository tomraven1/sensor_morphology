% Solve an Input-Output Fitting problem with a Neural Network
% Script generated by Neural Fitting app
% Created 25-Jun-2019 12:08:24
%
% This script assumes these variables are defined:
%
%   sens_raw_all - input data.
%   loc_all - target data.
%sens_raw_all=normalize(sens_raw_all,'range',[0  K.resolution]);
%sens_raw_all=ceil(sens_raw_all);
L=length(yn_m);
L=1190;
L=2490;
% x=[y_m(1:L,:)';yo_m(1:L,:)'];
% x=[y_v(1:L,:)';yo_v(1:L,:)'];



%x=[y_v(1:L,:)';yo_v(1:L,:)';yn_v(1:L,:)'];

for i=1
    combs=  combnk(1:6,7-i);
    for k=1: size(combs,1)
       % x=[y_v(200:L,combs(k,:))';yo_v(200:L,combs(k,:))';yn_v(200:L,combs(k,:))'];
        x=[yo_m(100:L,combs(k,:))';yn_m(100:L,combs(k,:))'];
       % x=[y_v(1:L,combs(k,:))'];
        %x = sens_raw_all'+rand(size(sens_raw_all'))/1000000;
       % x=x(combs(k,:),:);
        t = pos(:,100:L);
        %t=t(2,:);
        
        %x=x(1:6,:);
        
        % Choose a Training Function
        % For a list of all training functions type: help nntrain
        % 'trainlm' is usually fastest.
        % 'trainbr' takes longer but may be better for challenging problems.
        % 'trainscg' uses less memory. Suitable in low memory situations.
        trainFcn = 'trainlm';  % Levenberg-Marquardt backpropagation.
        
        % Create a Fitting Network
        hiddenLayerSize = [40];
        net = fitnet(hiddenLayerSize,trainFcn);
        net.trainParam.epochs=500;
        % Choose Input and Output Pre/Post-Processing Functions
        % For a list of all processing functions type: help nnprocess
        net.input.processFcns = {'removeconstantrows','mapminmax'};
        net.output.processFcns = {'removeconstantrows','mapminmax'};
        
        %net.input.processFcns = {'mapminmax'};
        %net.output.processFcns = {'mapminmax'};
         net.trainParam.max_fail = 6;
        % Setup Division of Data for Training, Validation, Testing
        % For a list of all data division functions type: help nndivision
        net.divideFcn = 'dividerand';  % Divide data randomly
        net.divideMode = 'sample';  % Divide up every sample
        net.divideParam.trainRatio = 70/100;
        net.divideParam.valRatio = 15/100;
        net.divideParam.testRatio = 15/100;
        
        % Choose a Performance Function
        % For a list of all performance functions type: help nnperformance
        net.performFcn = 'mse';  % Mean Squared Error
        
        % Choose Plot Functions
        % For a list of all plot functions type: help nnplot
        net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
            'plotregression', 'plotfit'};
        
        % Train the Network
        [net,tr] = train(net,x,t);
        
        % Test the Network
        y = net(x);
        
        err=(rssq(y-t));
        
        err_all(i,k)=mean(rssq(y-t));
    end
end

 x1=x(:,tr.testInd);
 %x1(3,:)=0;

 y = net(x1);
 err_t=(rssq(y-t(:,tr.testInd)));
 pointsize=50;
 %scatter(t(1,tr.testInd),t(2,tr.testInd), pointsize, err_t,'filled');
 
%
% 
% autoenc = trainAutoencoder(sens_raw_all',7);
% 
% z= predict(autoenc,sens_raw_all');
% mean(rssq(sens_raw_all'-z))
% 
% y = net(z);
% mean(rssq(y-t))
% 
% % plot(z(3,1:100))
% % hold on
% % plot(x(3,1:100))

% a='b';
% plot(err_all(1,:),a)
% hold on
% plot(err_all(2,:),a)
% plot(err_all(3,:),a)

% 

for i=1:4
    %scatter (kkk,mean(nonzeros(err_all(i,:))),'b')
    %scatter (kkk,std(nonzeros(err_all(i,:))),'b')
    m_err(i)=mean(nonzeros(err_all(i,:)));
    d_err(i)=std(nonzeros(err_all(i,:)));
    %hold on
end
%kkk=kkk+1;
errorbar(  m_err,  d_err)
hold on